{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_sent_emo.csv', index_col=0)\n",
    "df_dev = pd.read_csv('dev_sent_emo.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert utt to str\n",
    "df_train['Utterance'] = df_train['Utterance'].astype(str)\n",
    "df_dev['Utterance'] = df_dev['Utterance'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column named 'image_names' in the DataFrame to store the image file names\n",
    "\n",
    "df_train['image_names'] = df_train.apply(lambda row: f'dia{row[\"Dialogue_ID\"]}_utt{row[\"Utterance_ID\"]}', axis=1)\n",
    "df_dev['image_names'] = df_dev.apply(lambda row: f'dia{row[\"Dialogue_ID\"]}_utt{row[\"Utterance_ID\"]}', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "path_anger = cwd + '/BPI-MELD-main/BPI-MELD-main/train/train_splits_images/anger_oneface/'\n",
    "path_joy = cwd + '/BPI-MELD-main/BPI-MELD-main/train/train_splits_images/joy_oneface/'\n",
    "path_neutral = cwd + '/BPI-MELD-main/BPI-MELD-main/train/train_splits_images/neutral_oneface/'\n",
    "path_anger_dev = cwd + '/BPI-MELD-main/BPI-MELD-main/dev/dev_splits_images/anger_oneface/'\n",
    "path_joy_dev = cwd + '/BPI-MELD-main/BPI-MELD-main/dev/dev_splits_images/joy_oneface/'\n",
    "path_neutral_dev = cwd + '/BPI-MELD-main/BPI-MELD-main/dev/dev_splits_images/neutral_oneface/'\n",
    "\n",
    "files_anger = glob.glob(os.path.join(path_anger, '*.jpg'))\n",
    "files_joy = glob.glob(os.path.join(path_joy, '*.jpg'))\n",
    "files_neutral = glob.glob(os.path.join(path_neutral, '*.jpg'))\n",
    "files_anger_dev = glob.glob(os.path.join(path_anger_dev, '*.jpg'))\n",
    "files_joy_dev = glob.glob(os.path.join(path_joy_dev, '*.jpg'))\n",
    "files_neutral_dev = glob.glob(os.path.join(path_neutral_dev, '*.jpg'))\n",
    "\n",
    "files_anger = set([file.split(\"\\x5c\")[-1][:-6] for file in files_anger])\n",
    "files_joy = set([file.split(\"\\x5c\")[-1][:-6] for file in files_joy])\n",
    "files_neutral = set([file.split(\"\\x5c\")[-1][:-6] for file in files_neutral])\n",
    "files_anger_dev = set([file.split(\"\\x5c\")[-1][:-6] for file in files_anger_dev])\n",
    "files_joy_dev = set([file.split(\"\\x5c\")[-1][:-6] for file in files_joy_dev])\n",
    "files_neutral_dev = set([file.split(\"\\x5c\")[-1][:-6] for file in files_neutral_dev])\n",
    "\n",
    "all_files = files_anger.union(files_joy).union(files_neutral)\n",
    "all_files_dev = files_anger_dev.union(files_joy_dev).union(files_neutral_dev)\n",
    "\n",
    "print(len(all_files))\n",
    "print(len(all_files_dev))\n",
    "\n",
    "# all_files_train_dev = all_files.union(all_files_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['image_names'].isin(list(all_files))]\n",
    "df_dev = df_dev[df_dev['image_names'].isin(list(all_files_dev))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    1460\n",
       "joy        1145\n",
       "anger       770\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral    129\n",
       "anger      120\n",
       "joy        110\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def clean(text_list, lemmatize, stem, stopwords):\n",
    "\n",
    "    updates = []\n",
    "\n",
    "    for j in tqdm(text_list):\n",
    "\n",
    "        text = str(j)\n",
    "        #Regular expressions:\n",
    "\n",
    "        #LOWERCASE TEXT\n",
    "        text = text.lower()\n",
    "        # Remove special characters and punctuations\n",
    "        # text = re.sub('[^a-zA-Z0-9\\s]', '', text)\n",
    "        # text = re.sub(\"br\", \"\", text)\n",
    "        # text = re.sub(\"x000d\", \"\", text)\n",
    "        # text = re.sub(\"x000D\", \"\", text)\n",
    "        # Remove HTML tags\n",
    "        # text = re.sub('<.*?>', '', text)\n",
    "        # Remove extra whitespaces\n",
    "        text = re.sub('\\s+', ' ', text).strip()\n",
    "\n",
    "        #REMOVE STOPWORDS\n",
    "        if stopwords:\n",
    "\n",
    "          text = \" \".join([word for word in text.split() if word not in stop])\n",
    "\n",
    "        #Lemmatize\n",
    "        if lemmatize:\n",
    "          text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "\n",
    "        #Stemming\n",
    "        if stem:\n",
    "          text = \" \".join(stemmer.stem(word) for word in text.split() if word)\n",
    "\n",
    "\n",
    "        updates.append(text)\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3375/3375 [00:01<00:00, 3078.10it/s]\n",
      "100%|██████████| 359/359 [00:00<00:00, 51306.91it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['Utterance_cleaned'] = clean(df_train['Utterance'] , lemmatize=True, stem=False, stopwords=True)\n",
    "df_dev['Utterance_cleaned'] = clean(df_dev['Utterance'] , lemmatize=True, stem=False, stopwords=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fast_text = df_train.copy()\n",
    "df_fast_text_dev = df_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_fast_text['Emotion']\n",
    "y_test = df_fast_text_dev['Emotion']\n",
    "\n",
    "#save image_names to use latter\n",
    "image_names = df_fast_text['image_names']\n",
    "image_names_dev = df_fast_text_dev['image_names']\n",
    "\n",
    "df_fast_text.drop(columns=['Emotion', 'image_names'], inplace=True)\n",
    "df_fast_text_dev.drop(columns=['Emotion', 'image_names'], inplace=True)\n",
    "\n",
    "X_train_ft = df_fast_text.copy()\n",
    "X_test_ft = df_fast_text_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import tensorflow as tf\n",
    "\n",
    "model_ft = FastText(sentences = X_train_ft.Utterance_cleaned, min_count = 1, vector_size = 300, sg = 0, cbow_mean = 1, hs = 1,\n",
    "                    window = 5, alpha = 0.05, min_alpha = 0.0001, negative = 4, epochs = 35, sample = 1e-3, workers = 1, seed = 1, batch_words = 75,\n",
    "                    min_n = 2, max_n = 4)\n",
    "\n",
    "train_vectors = [[model_ft.wv[word] for word in text] for text in X_train_ft['Utterance_cleaned']]       \n",
    "    \n",
    "pad_len = 20\n",
    "\n",
    "train_vectors = tf.keras.utils.pad_sequences(train_vectors, maxlen = pad_len, dtype='float32', padding='post', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vectors = [[model_ft.wv[word] for word in text] \n",
    "                 for text in X_test_ft['Utterance_cleaned']]  \n",
    "\n",
    "val_vectors = tf.keras.utils.pad_sequences(val_vectors, maxlen = pad_len, dtype='float32', padding='post', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = y_train.replace({'neutral':0,'anger':1,'joy':2})\n",
    "y_val_cat = y_test.replace({'neutral':0,'anger':1,'joy':2})\n",
    "\n",
    "y_train_cat = to_categorical(y_train_cat)\n",
    "y_val_cat = to_categorical(y_val_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Flatten, Concatenate, Dense, Bidirectional, LSTM, Dropout, InputLayer, Conv1D, Conv2D, MaxPool1D, MaxPool2D, Masking, TimeDistributed, Attention, Activation\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "precision, recall = Precision(), Recall()\n",
    "\n",
    "def get_model (lr):\n",
    "\n",
    "    text = Input(shape = (20, 300))\n",
    "    lstm1 = Bidirectional(LSTM(300, return_sequences = False, input_shape = (20, 300), dropout=0.3))(text)\n",
    "    dense = Dense(3, activation = 'softmax')(lstm1)\n",
    "    \n",
    "    model = keras.Model(inputs=text, outputs=dense, name=\"Context_bLSTM_text_model\")\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate = lr), metrics=['accuracy', precision, recall], sample_weight_mode='temporal', weighted_metrics=[])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Context_bLSTM_text_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 300)]         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 600)               1442400   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 1803      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1444203 (5.51 MB)\n",
      "Trainable params: 1444203 (5.51 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model(lr=0.01)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.0608 - accuracy: 0.4536 - precision: 0.5161 - recall: 0.0142\n",
      "Epoch 1: val_loss improved from inf to 1.10189, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 13s 160ms/step - loss: 1.0608 - accuracy: 0.4536 - precision: 0.5161 - recall: 0.0142 - val_loss: 1.1019 - val_accuracy: 0.4290 - val_precision: 0.2500 - val_recall: 0.0139\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 1.0030 - accuracy: 0.5289 - precision: 0.6179 - recall: 0.1576\n",
      "Epoch 2: val_loss did not improve from 1.10189\n",
      "53/53 [==============================] - 8s 146ms/step - loss: 1.0030 - accuracy: 0.5289 - precision: 0.6179 - recall: 0.1576 - val_loss: 1.1053 - val_accuracy: 0.4735 - val_precision: 0.4375 - val_recall: 0.2730\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9672 - accuracy: 0.5508 - precision: 0.6126 - recall: 0.3079\n",
      "Epoch 3: val_loss improved from 1.10189 to 1.02423, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 8s 144ms/step - loss: 0.9672 - accuracy: 0.5508 - precision: 0.6126 - recall: 0.3079 - val_loss: 1.0242 - val_accuracy: 0.4540 - val_precision: 0.5339 - val_recall: 0.1755\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9470 - accuracy: 0.5594 - precision: 0.6369 - recall: 0.3399\n",
      "Epoch 4: val_loss did not improve from 1.02423\n",
      "53/53 [==============================] - 8s 148ms/step - loss: 0.9470 - accuracy: 0.5594 - precision: 0.6369 - recall: 0.3399 - val_loss: 1.0296 - val_accuracy: 0.4763 - val_precision: 0.5123 - val_recall: 0.2897\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9375 - accuracy: 0.5644 - precision: 0.6399 - recall: 0.3849\n",
      "Epoch 5: val_loss did not improve from 1.02423\n",
      "53/53 [==============================] - 9s 163ms/step - loss: 0.9375 - accuracy: 0.5644 - precision: 0.6399 - recall: 0.3849 - val_loss: 1.0454 - val_accuracy: 0.4819 - val_precision: 0.4922 - val_recall: 0.3510\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9266 - accuracy: 0.5701 - precision: 0.6430 - recall: 0.3896\n",
      "Epoch 6: val_loss did not improve from 1.02423\n",
      "53/53 [==============================] - 9s 165ms/step - loss: 0.9266 - accuracy: 0.5701 - precision: 0.6430 - recall: 0.3896 - val_loss: 1.0393 - val_accuracy: 0.4708 - val_precision: 0.4886 - val_recall: 0.3593\n",
      "Epoch 1/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.0213 - accuracy: 0.4951 - precision: 0.5709 - recall: 0.2619\n",
      "Epoch 1: val_loss improved from inf to 1.06588, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 13s 181ms/step - loss: 1.0213 - accuracy: 0.4951 - precision: 0.5709 - recall: 0.2619 - val_loss: 1.0659 - val_accuracy: 0.4290 - val_precision: 0.4823 - val_recall: 0.1894\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9339 - accuracy: 0.5609 - precision: 0.6410 - recall: 0.3867\n",
      "Epoch 2: val_loss improved from 1.06588 to 1.01442, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 9s 164ms/step - loss: 0.9339 - accuracy: 0.5609 - precision: 0.6410 - recall: 0.3867 - val_loss: 1.0144 - val_accuracy: 0.4903 - val_precision: 0.5126 - val_recall: 0.3955\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9176 - accuracy: 0.5760 - precision: 0.6387 - recall: 0.4264\n",
      "Epoch 3: val_loss did not improve from 1.01442\n",
      "53/53 [==============================] - 9s 161ms/step - loss: 0.9176 - accuracy: 0.5760 - precision: 0.6387 - recall: 0.4264 - val_loss: 1.0186 - val_accuracy: 0.5097 - val_precision: 0.5401 - val_recall: 0.3565\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.8908 - accuracy: 0.5970 - precision: 0.6609 - recall: 0.4527\n",
      "Epoch 4: val_loss did not improve from 1.01442\n",
      "53/53 [==============================] - 9s 165ms/step - loss: 0.8908 - accuracy: 0.5970 - precision: 0.6609 - recall: 0.4527 - val_loss: 1.0322 - val_accuracy: 0.4930 - val_precision: 0.5333 - val_recall: 0.3120\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.8778 - accuracy: 0.5935 - precision: 0.6630 - recall: 0.4785\n",
      "Epoch 5: val_loss improved from 1.01442 to 1.00966, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 9s 165ms/step - loss: 0.8778 - accuracy: 0.5935 - precision: 0.6630 - recall: 0.4785 - val_loss: 1.0097 - val_accuracy: 0.5014 - val_precision: 0.5481 - val_recall: 0.3649\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.6246 - precision: 0.6803 - recall: 0.5159\n",
      "Epoch 6: val_loss did not improve from 1.00966\n",
      "53/53 [==============================] - 9s 164ms/step - loss: 0.8458 - accuracy: 0.6246 - precision: 0.6803 - recall: 0.5159 - val_loss: 1.0525 - val_accuracy: 0.4819 - val_precision: 0.5108 - val_recall: 0.3955\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.7988 - accuracy: 0.6456 - precision: 0.6974 - recall: 0.5627\n",
      "Epoch 7: val_loss did not improve from 1.00966\n",
      "53/53 [==============================] - 9s 165ms/step - loss: 0.7988 - accuracy: 0.6456 - precision: 0.6974 - recall: 0.5627 - val_loss: 1.0805 - val_accuracy: 0.4847 - val_precision: 0.5152 - val_recall: 0.4262\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.7511 - accuracy: 0.6696 - precision: 0.7203 - recall: 0.6006\n",
      "Epoch 8: val_loss did not improve from 1.00966\n",
      "53/53 [==============================] - 9s 167ms/step - loss: 0.7511 - accuracy: 0.6696 - precision: 0.7203 - recall: 0.6006 - val_loss: 1.1149 - val_accuracy: 0.5181 - val_precision: 0.5288 - val_recall: 0.4345\n",
      "Epoch 1/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.1839 - accuracy: 0.4237 - precision: 0.4787 - recall: 0.1926\n",
      "Epoch 1: val_loss improved from inf to 1.09159, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 13s 184ms/step - loss: 1.1839 - accuracy: 0.4237 - precision: 0.4787 - recall: 0.1926 - val_loss: 1.0916 - val_accuracy: 0.4039 - val_precision: 0.5750 - val_recall: 0.1281\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.0002 - accuracy: 0.5212 - precision: 0.5923 - recall: 0.3470\n",
      "Epoch 2: val_loss improved from 1.09159 to 1.06078, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 8s 157ms/step - loss: 1.0002 - accuracy: 0.5212 - precision: 0.5923 - recall: 0.3470 - val_loss: 1.0608 - val_accuracy: 0.3983 - val_precision: 0.4859 - val_recall: 0.1922\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9419 - accuracy: 0.5692 - precision: 0.6251 - recall: 0.4154\n",
      "Epoch 3: val_loss did not improve from 1.06078\n",
      "53/53 [==============================] - 8s 154ms/step - loss: 0.9419 - accuracy: 0.5692 - precision: 0.6251 - recall: 0.4154 - val_loss: 1.0922 - val_accuracy: 0.4708 - val_precision: 0.4659 - val_recall: 0.3621\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.9206 - accuracy: 0.5707 - precision: 0.6295 - recall: 0.4436\n",
      "Epoch 4: val_loss improved from 1.06078 to 1.00625, saving model to weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\n",
      "53/53 [==============================] - 8s 150ms/step - loss: 0.9206 - accuracy: 0.5707 - precision: 0.6295 - recall: 0.4436 - val_loss: 1.0062 - val_accuracy: 0.5070 - val_precision: 0.5419 - val_recall: 0.3426\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.8984 - accuracy: 0.5867 - precision: 0.6447 - recall: 0.4501\n",
      "Epoch 5: val_loss did not improve from 1.00625\n",
      "53/53 [==============================] - 8s 146ms/step - loss: 0.8984 - accuracy: 0.5867 - precision: 0.6447 - recall: 0.4501 - val_loss: 1.0376 - val_accuracy: 0.5181 - val_precision: 0.5242 - val_recall: 0.3928\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.8599 - accuracy: 0.6083 - precision: 0.6699 - recall: 0.4930\n",
      "Epoch 6: val_loss did not improve from 1.00625\n",
      "53/53 [==============================] - 8s 148ms/step - loss: 0.8599 - accuracy: 0.6083 - precision: 0.6699 - recall: 0.4930 - val_loss: 1.0963 - val_accuracy: 0.4819 - val_precision: 0.5058 - val_recall: 0.3621\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.8446 - accuracy: 0.6187 - precision: 0.6808 - recall: 0.5081\n",
      "Epoch 7: val_loss did not improve from 1.00625\n",
      "53/53 [==============================] - 8s 145ms/step - loss: 0.8446 - accuracy: 0.6187 - precision: 0.6808 - recall: 0.5081 - val_loss: 1.0457 - val_accuracy: 0.4708 - val_precision: 0.5057 - val_recall: 0.3677\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.0001,0.005,0.01]\n",
    "\n",
    "for l_r in learning_rates:\n",
    "    \n",
    "    Ind_text_Context_LSTM_model_lr_fasttext = get_model(lr=l_r)\n",
    "    \n",
    "    filepath=\"weights_Ind_text_Context_LSTM_model_lr_fasttext.best.hdf5\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, restore_best_weights=True)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "\n",
    "    hist = Ind_text_Context_LSTM_model_lr_fasttext.fit(train_vectors, y_train_cat, validation_data=(val_vectors, y_val_cat), \n",
    "                    callbacks=callbacks_list, epochs=10, batch_size=64, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 36ms/step\n",
      "Independent LSTM Accuracy Score ->  50.69637883008357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "\n",
    "pred = (Ind_text_Context_LSTM_model_lr_fasttext.predict(val_vectors))\n",
    "\n",
    "true_label=[]\n",
    "predicted_label=[]\n",
    "\n",
    "for i in range(pred.shape[0]):\n",
    "\ttrue_label.append(np.argmax(y_val_cat[i] ))\n",
    "\tpredicted_label.append(np.argmax(pred[i]))\n",
    "            \n",
    "print(\"Independent LSTM Accuracy Score -> \",accuracy_score(predicted_label, true_label)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.84      0.64       129\n",
      "           1       0.49      0.33      0.40       120\n",
      "           2       0.51      0.31      0.38       110\n",
      "\n",
      "    accuracy                           0.51       359\n",
      "   macro avg       0.50      0.49      0.47       359\n",
      "weighted avg       0.50      0.51      0.48       359\n",
      "\n",
      "Weighted Scores: \n",
      "  (0.5033435599752057, 0.5069637883008357, 0.4790510577893703, None)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report :\")\n",
    "print(classification_report(true_label, predicted_label))\n",
    "print('Weighted Scores: \\n ', precision_recall_fscore_support(true_label, predicted_label, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Neutral', 'Anger', 'joy']\n",
    "\n",
    "cf = confusion_matrix(true_label, predicted_label)\n",
    "disp = ConfusionMatrixDisplay(cf, display_labels=labels)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "print(K.eval(Ind_text_Context_LSTM_model_lr_fasttext.optimizer.lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>image_names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sr No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why do all you’re coffee mugs have numbers on ...</td>\n",
       "      <td>Mark</td>\n",
       "      <td>surprise</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>00:14:38,127</td>\n",
       "      <td>00:14:40,378</td>\n",
       "      <td>dia0_utt0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh. That’s so Monica can keep track. That way ...</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>00:14:40,629</td>\n",
       "      <td>00:14:47,385</td>\n",
       "      <td>dia0_utt1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y'know what?</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>00:14:56,353</td>\n",
       "      <td>00:14:57,520</td>\n",
       "      <td>dia0_utt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Come on, Lydia, you can do it.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0:10:44,769</td>\n",
       "      <td>0:10:46,146</td>\n",
       "      <td>dia1_utt0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Push!</td>\n",
       "      <td>Joey</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0:10:46,146</td>\n",
       "      <td>0:10:46,833</td>\n",
       "      <td>dia1_utt1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>Yeah, I mean, come on Ross, no one will even n...</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>279</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:14:35,457</td>\n",
       "      <td>00:14:40,211</td>\n",
       "      <td>dia279_utt11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>They’re not listening too me?</td>\n",
       "      <td>Ross</td>\n",
       "      <td>surprise</td>\n",
       "      <td>none</td>\n",
       "      <td>279</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:14:42,256</td>\n",
       "      <td>00:14:43,840</td>\n",
       "      <td>dia279_utt12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>Of course they’re listening to you! Everybody ...</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>279</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:14:44,008</td>\n",
       "      <td>00:14:48,511</td>\n",
       "      <td>dia279_utt13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>Monica you really think I should try this phas...</td>\n",
       "      <td>Ross</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>279</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:14:48,138</td>\n",
       "      <td>00:14:52,390</td>\n",
       "      <td>dia279_utt14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>I think you look fine.</td>\n",
       "      <td>Monica</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>279</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>00:14:52,558</td>\n",
       "      <td>00:14:54,183</td>\n",
       "      <td>dia279_utt15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Utterance Speaker   Emotion  \\\n",
       "Sr No.                                                                        \n",
       "1       Why do all you’re coffee mugs have numbers on ...    Mark  surprise   \n",
       "2       Oh. That’s so Monica can keep track. That way ...  Rachel      none   \n",
       "3                                            Y'know what?  Rachel      none   \n",
       "19                         Come on, Lydia, you can do it.    Joey      none   \n",
       "20                                                  Push!    Joey      none   \n",
       "...                                                   ...     ...       ...   \n",
       "2760    Yeah, I mean, come on Ross, no one will even n...  Rachel      none   \n",
       "2761                        They’re not listening too me?    Ross  surprise   \n",
       "2762    Of course they’re listening to you! Everybody ...  Rachel      none   \n",
       "2763    Monica you really think I should try this phas...    Ross      none   \n",
       "2764                               I think you look fine.  Monica      none   \n",
       "\n",
       "       Sentiment  Dialogue_ID  Utterance_ID  Season  Episode     StartTime  \\\n",
       "Sr No.                                                                       \n",
       "1           none            0             0       3       19  00:14:38,127   \n",
       "2           none            0             1       3       19  00:14:40,629   \n",
       "3           none            0             2       3       19  00:14:56,353   \n",
       "19          none            1             0       1       23   0:10:44,769   \n",
       "20          none            1             1       1       23   0:10:46,146   \n",
       "...          ...          ...           ...     ...      ...           ...   \n",
       "2760        none          279            11       6        4  00:14:35,457   \n",
       "2761        none          279            12       6        4  00:14:42,256   \n",
       "2762        none          279            13       6        4  00:14:44,008   \n",
       "2763        none          279            14       6        4  00:14:48,138   \n",
       "2764        none          279            15       6        4  00:14:52,558   \n",
       "\n",
       "             EndTime   image_names  \n",
       "Sr No.                              \n",
       "1       00:14:40,378     dia0_utt0  \n",
       "2       00:14:47,385     dia0_utt1  \n",
       "3       00:14:57,520     dia0_utt2  \n",
       "19       0:10:46,146     dia1_utt0  \n",
       "20       0:10:46,833     dia1_utt1  \n",
       "...              ...           ...  \n",
       "2760    00:14:40,211  dia279_utt11  \n",
       "2761    00:14:43,840  dia279_utt12  \n",
       "2762    00:14:48,511  dia279_utt13  \n",
       "2763    00:14:52,390  dia279_utt14  \n",
       "2764    00:14:54,183  dia279_utt15  \n",
       "\n",
       "[2610 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_sent_emo.csv', index_col=0)\n",
    "df_test['image_names'] = df_test.apply(lambda row: f'dia{row[\"Dialogue_ID\"]}_utt{row[\"Utterance_ID\"]}', axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2610/2610 [00:00<00:00, 49216.97it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test['Utterance_cleaned'] = clean(df_test['Utterance'] , lemmatize=True, stem=False, stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = [[model_ft.wv[word] for word in text] \n",
    "                 for text in df_test['Utterance']]  \n",
    "\n",
    "test_vectors = tf.keras.utils.pad_sequences(test_vectors, maxlen = pad_len, dtype='float32', padding='post', truncating='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 3s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_final = (Ind_text_Context_LSTM_model_lr_fasttext.predict(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_final = []\n",
    "\n",
    "for i in range(pred_final.shape[0]):\n",
    "\tpredicted_label_final.append(np.argmax(pred_final[i]))\n",
    "\n",
    "final_predictions = pd.DataFrame(predicted_label_final, columns = ['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['image_names'] = df_test['image_names'] + ','\n",
    "\n",
    "final_predictions = pd.concat([df_test['image_names'].reset_index(drop=True), final_predictions], axis=1)\n",
    "\n",
    "final_predictions = final_predictions.replace({0:'neutral',1:'anger',2:'joy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['dia0_utt0,', 'neutral'],\n",
       "       ['dia0_utt1,', 'neutral'],\n",
       "       ['dia0_utt2,', 'neutral'],\n",
       "       ...,\n",
       "       ['dia279_utt13,', 'joy'],\n",
       "       ['dia279_utt14,', 'neutral'],\n",
       "       ['dia279_utt15,', 'joy']], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'C:\\\\Users\\\\USER\\\\Desktop\\\\BPI\\\\Week 7\\\\projeto\\\\NLP_lstm.txt', final_predictions.values, fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
